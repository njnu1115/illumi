作者：欧阳洋葱
链接：https://www.zhihu.com/question/448243614/answer/1798651324
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

最近看了点 MCM GPU 的东西...算是从某一个角度来答这个问题吧。

我们知道，比较符合直觉来弹性扩展 GPU 算力的方案，应该是多显卡。如果单纯说游戏图形计算的话，其实也就是 3dfx 时期就有的 SLI（或者 AMD 的 CrossFire）一类，虽然可能在实现细节上，现在和过去是大不一样了。不过堆砌计算资源，总归就是这样的思路。

现在的消费电子市场的 GPU，单 die 尺寸越来越接近光刻机的 reticle limit，也就是光刻机可处理的最大尺寸。比如 GeForce RTX 3090，芯片之上的那片 die，尺寸达到了 628mm²。就不说良率和成本问题，这个尺寸也还有扩大的可行性——而且毕竟制造工艺还在进步，所以单位面积内可容纳的计算单元也还能扩展。

不过这个单 die 尺寸其实也已经比较夸张了。何况摩尔定律不是放缓吗？所以 monolithic（也就是单 die）GPU 也在接近某种极限。

所以人们自然想到的，应该是如何更高效扩展算力。直觉上就如前面提到的，就是系统级的多显卡方案，或者也可以是板级的多芯方案（就是一块 GPU 显卡上，有多颗封装的芯片）。系统级多显卡在数据中心市场本来就很常见，AI 芯片基本上也这么扩展算力。

不过在游戏相关的图形计算市场，多 GPU 并不是什么受欢迎的方案。我觉得一方面是对开发者而言，开发会变得更麻烦；另一方面则是，系统级或者板级的不同计算硬件之间，要做通讯、存储一致性，也不是那么好做——效率和性能都远远做不到 1+1 = 2 的程度，但投入的成本却又实打实的还挺高。

<img src="https://pic1.zhimg.com/50/v2-d96e3f0581e3bc18611d58873faa62fe.jpg">


这个时候，MCM GPU 就成为一个方向了，MCM 就是 multi chip module。MCM 通常描述封装级的，将几个 die 放到同一个 substrate 上（封装方式有很多，也有把 MCM/Multi-chip Package 更狭义地定义为某一种封装方式）。用现在比较流行的话来说，每一片 die 就是一个 chiplet（好像比较流行译作“芯粒”）。也就是原本一片大 die，切分成很多的小 die，把它们连起来，当然通常还需要做互联的组成部分，以及对应的总线技术之类的，再把它们封装成一颗芯片。

AMD 目前的 Zen 架构锐龙处理器（CPU），就在用这种方案。所以我们在消费市场上，很轻易就能见到 16、32、64 核处理器。起码 chiplet/MCM 这种方案，对于堆核心肯定是会更有帮助的。（当然其实不同处理或 I/O 单元的 chiplet，在很多芯片上都相当常见了，比如 Intel 处理器常见的 CPU die 和 PCH die；或者 Kaby Lake G 那种 CPU 和 GPU die 分开；或者 GPU 芯片之上还可能把 HBM 封装进去）

<img src="https://pic1.zhimg.com/50/v2-bc731fc9f10af75b86237e76288b4fe3.jpg">来源：TechPowerUp，侵删


这种把 monolithic 切分成很多 chiplet 的方案，也就很大程度回避了 reticle limit 限制，可以比较具有弹性地堆计算资源。关键是成本可以比单 die 方案显著降低，因为晶圆切割到更小的单元，晶圆利用率本身就在提高，而且良率也会提高（切大 die 的良率和成本是比较可怕的）。

即便是加上互联 I/O die（Zen 2），成本也比 monolithic 要低。前不久的 ISSCC 上，AMD 有提到，以 chiplet 方案来造 Epyc 处理器，能够比单 die 方案节省 41% 的成本。这个具体是怎么样一个环境，有兴趣的可以去查一下。

虽然 MCM GPU 仍然存在不少待解决的问题（此前 AMD 曾提过，MCM 应用于 GPU，难度会比 CPU 要大；主要是对于图形计算），就从直觉来看，在一个 MCM GPU 上渲染游戏画面帧，但却要分配到不同的 chiplet，还是需要花很多工夫的。不过它至少在效率、性能提升方面，会显著的高于以前那种系统级、板级多 GPU 方案。

<img src="https://pic4.zhimg.com/50/v2-22c23bd6b6bbf44b3bb82b5f020feda7.jpg">


上面这张图来自英伟达此前发布的一篇 paper，比较 MCM GPU 相比多 GPU 和 monolithic 方案的性能差异。这里的 monolithic GPU 是假想中的某个大 die 的 GPU，它实际上是造不出来的（因为前面提到制造上的限制）。

不过这篇 paper 所述的这种 MCM GPU，其实他们也并没有实际造出来，而是用某个复杂系统模拟出来的。其中还加了英伟达的一些优化方案，探讨了缓存一致性、互联之类的问题；另外英伟达也提到当代技术趋于成熟，为造 MCM GPU 奠定了一定的实现基础


详情参见：MCM-GPU: Multi-Chip-Module GPUs for Continued Performance Scalability<img src="https://pic1.zhimg.com/50/v2-a194e93f056eafdef87b6b6aec85978d.jpg">


另外 AMD 在 2019 年申请过一项专利，叫 GPU Chiplets using High Bandwidth Crosslinks。今年 1 月份国外媒体也都报道了。我感觉这套方案试图解决 MCM GPU 对于游戏开发者而言编程难的问题。

这套系统里面，和 CPU 连接的就只有第一颗 GPU chiplet。其余的 GPU chiplet 彼此之间用所谓的 passive crosslink 来连接；当然还有一些 cache 层级方案之类。对于 CPU 而言，这个 GPU 系统感觉上就像是个 monolithic 的 GPU 一样，因为它发出请求只面向一颗 chiplet。当然这可能也只是个专利储备。

所以 MCM GPU 会成为突破极限的一个很好的方案吧，虽然貌似还没什么东西出来（其实 2019 年的时候，英伟达已经造出了 MCM 形态的 AI 芯片，叫 RC18，也可以看做是 MCM GPU 的某种雏形吧）。

Intel 今年初还在推特上发过一张 Xe-HPC GPU 的图片了（产品本身尚未发布），看起来就是个 chiplet 方案的 GPU——虽然面向的并非消费用户群体。其实这种 MCM GPU 对于 HPC、数据中心大规模集群而言是明显更具适配性的，主要是提升性能密度，并且在通讯、供电、制冷方面，相比系统级的多 GPU 方案，是能明显缩减能源开销的。

预期未来 MCM GPU 会首先在数据中心问世吧，随后再逐步下放到游戏图形计算市场。非相关业内人士，仅现成内容的呈现。

编辑于 03-26